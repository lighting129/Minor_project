{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_ZqPbfsPgp8L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
            "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-16 23:27:29.744746: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xQWaiIPvhR7v"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/Users/devrajjajoo/Downloads/fer2013.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uusoIOCTq0qh",
        "outputId": "be177f7c-9409-4a32-da9d-9043c151d0b4"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "for index, row in data.iterrows():\n",
        "    pixel_values = row['pixels'].split(' ')\n",
        "    pixel_values = np.array(pixel_values, dtype='float32')\n",
        "\n",
        "\n",
        "    if pixel_values.shape[0] == 2304:\n",
        "        image = pixel_values.reshape(48, 48, 1)\n",
        "        X.append(image)\n",
        "        y.append(row['emotion'])\n",
        "    else:\n",
        "        print(f\"Skipping row {index} due to unexpected pixel values shape: {pixel_values.shape}\")\n",
        "\n",
        "X = np.array(X) / 255.0\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UcpQ1FXOq1Lz"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GJH6fEmTDqmC"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5vhS3XzBDsx1"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff-w3578DwLx",
        "outputId": "af133f39-1538-4d7c-8511-e478f195abf3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=Adam(lr=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUbXqsBCDzyT",
        "outputId": "53fdaaca-a6b0-4a40-8bc6-7ee7fcc5039a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-16 23:28:58.707596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "448/448 [==============================] - 25s 53ms/step - loss: 1.7958 - accuracy: 0.2580 - val_loss: 1.6868 - val_accuracy: 0.3260\n",
            "Epoch 2/50\n",
            "448/448 [==============================] - 23s 51ms/step - loss: 1.6842 - accuracy: 0.3275 - val_loss: 1.5350 - val_accuracy: 0.3975\n",
            "Epoch 3/50\n",
            "448/448 [==============================] - 24s 54ms/step - loss: 1.5548 - accuracy: 0.3953 - val_loss: 1.4245 - val_accuracy: 0.4524\n",
            "Epoch 4/50\n",
            "448/448 [==============================] - 23s 52ms/step - loss: 1.4673 - accuracy: 0.4355 - val_loss: 1.3122 - val_accuracy: 0.5091\n",
            "Epoch 5/50\n",
            "448/448 [==============================] - 24s 54ms/step - loss: 1.4136 - accuracy: 0.4582 - val_loss: 1.2862 - val_accuracy: 0.5132\n",
            "Epoch 6/50\n",
            "448/448 [==============================] - 23s 51ms/step - loss: 1.3781 - accuracy: 0.4751 - val_loss: 1.2520 - val_accuracy: 0.5198\n",
            "Epoch 7/50\n",
            "448/448 [==============================] - 23s 52ms/step - loss: 1.3465 - accuracy: 0.4883 - val_loss: 1.2281 - val_accuracy: 0.5340\n",
            "Epoch 8/50\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.3248 - accuracy: 0.4987 - val_loss: 1.2054 - val_accuracy: 0.5418\n",
            "Epoch 9/50\n",
            "448/448 [==============================] - 23s 51ms/step - loss: 1.3077 - accuracy: 0.4995 - val_loss: 1.2208 - val_accuracy: 0.5385\n",
            "Epoch 10/50\n",
            "448/448 [==============================] - 23s 52ms/step - loss: 1.2868 - accuracy: 0.5136 - val_loss: 1.1779 - val_accuracy: 0.5464\n",
            "Epoch 11/50\n",
            "448/448 [==============================] - 24s 54ms/step - loss: 1.2753 - accuracy: 0.5159 - val_loss: 1.1808 - val_accuracy: 0.5521\n",
            "Epoch 12/50\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.2628 - accuracy: 0.5218 - val_loss: 1.1489 - val_accuracy: 0.5638\n",
            "Epoch 13/50\n",
            "448/448 [==============================] - 24s 53ms/step - loss: 1.2554 - accuracy: 0.5224 - val_loss: 1.1506 - val_accuracy: 0.5690\n",
            "Epoch 14/50\n",
            "448/448 [==============================] - 24s 53ms/step - loss: 1.2374 - accuracy: 0.5328 - val_loss: 1.1543 - val_accuracy: 0.5574\n",
            "Epoch 15/50\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 1.2324 - accuracy: 0.5348 - val_loss: 1.1376 - val_accuracy: 0.5697\n",
            "Epoch 16/50\n",
            "448/448 [==============================] - 23s 52ms/step - loss: 1.2193 - accuracy: 0.5403 - val_loss: 1.1299 - val_accuracy: 0.5713\n",
            "Epoch 17/50\n",
            "448/448 [==============================] - 23s 51ms/step - loss: 1.2071 - accuracy: 0.5451 - val_loss: 1.1270 - val_accuracy: 0.5793\n",
            "Epoch 18/50\n",
            "448/448 [==============================] - 24s 53ms/step - loss: 1.1987 - accuracy: 0.5431 - val_loss: 1.1275 - val_accuracy: 0.5751\n",
            "Epoch 19/50\n",
            "448/448 [==============================] - 23s 52ms/step - loss: 1.1990 - accuracy: 0.5485 - val_loss: 1.1225 - val_accuracy: 0.5801\n",
            "Epoch 20/50\n",
            "448/448 [==============================] - 23s 51ms/step - loss: 1.1962 - accuracy: 0.5521 - val_loss: 1.1036 - val_accuracy: 0.5867\n",
            "Epoch 21/50\n",
            "448/448 [==============================] - 23s 52ms/step - loss: 1.1862 - accuracy: 0.5526 - val_loss: 1.1343 - val_accuracy: 0.5722\n",
            "Epoch 22/50\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.1800 - accuracy: 0.5538 - val_loss: 1.0871 - val_accuracy: 0.5906\n",
            "Epoch 23/50\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.1797 - accuracy: 0.5561 - val_loss: 1.1130 - val_accuracy: 0.5775\n",
            "Epoch 24/50\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.1729 - accuracy: 0.5579 - val_loss: 1.1042 - val_accuracy: 0.5825\n",
            "Epoch 25/50\n",
            "448/448 [==============================] - 30s 66ms/step - loss: 1.1687 - accuracy: 0.5604 - val_loss: 1.0788 - val_accuracy: 0.5942\n",
            "Epoch 26/50\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.1649 - accuracy: 0.5580 - val_loss: 1.0851 - val_accuracy: 0.5874\n",
            "Epoch 27/50\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.1536 - accuracy: 0.5643 - val_loss: 1.0921 - val_accuracy: 0.5878\n",
            "Epoch 28/50\n",
            "448/448 [==============================] - 24s 53ms/step - loss: 1.1562 - accuracy: 0.5610 - val_loss: 1.0896 - val_accuracy: 0.5939\n",
            "Epoch 29/50\n",
            "448/448 [==============================] - 21s 47ms/step - loss: 1.1511 - accuracy: 0.5628 - val_loss: 1.0786 - val_accuracy: 0.5946\n",
            "Epoch 30/50\n",
            "448/448 [==============================] - 21s 47ms/step - loss: 1.1478 - accuracy: 0.5681 - val_loss: 1.0715 - val_accuracy: 0.5947\n",
            "Epoch 31/50\n",
            "448/448 [==============================] - 22s 50ms/step - loss: 1.1477 - accuracy: 0.5692 - val_loss: 1.0770 - val_accuracy: 0.5938\n",
            "Epoch 32/50\n",
            "448/448 [==============================] - 21s 47ms/step - loss: 1.1382 - accuracy: 0.5718 - val_loss: 1.0756 - val_accuracy: 0.5974\n",
            "Epoch 33/50\n",
            "448/448 [==============================] - 21s 47ms/step - loss: 1.1379 - accuracy: 0.5728 - val_loss: 1.0788 - val_accuracy: 0.5947\n",
            "Epoch 34/50\n",
            "448/448 [==============================] - 22s 48ms/step - loss: 1.1354 - accuracy: 0.5726 - val_loss: 1.1049 - val_accuracy: 0.5793\n",
            "Epoch 35/50\n",
            "448/448 [==============================] - 22s 49ms/step - loss: 1.1258 - accuracy: 0.5754 - val_loss: 1.0779 - val_accuracy: 0.5965\n",
            "Epoch 36/50\n",
            "448/448 [==============================] - 21s 46ms/step - loss: 1.1262 - accuracy: 0.5772 - val_loss: 1.0912 - val_accuracy: 0.5931\n",
            "Epoch 37/50\n",
            "448/448 [==============================] - 21s 47ms/step - loss: 1.1225 - accuracy: 0.5767 - val_loss: 1.0654 - val_accuracy: 0.5961\n",
            "Epoch 38/50\n",
            "448/448 [==============================] - 21s 47ms/step - loss: 1.1235 - accuracy: 0.5748 - val_loss: 1.0809 - val_accuracy: 0.5917\n",
            "Epoch 39/50\n",
            "448/448 [==============================] - 21s 46ms/step - loss: 1.1167 - accuracy: 0.5800 - val_loss: 1.0851 - val_accuracy: 0.5939\n",
            "Epoch 40/50\n",
            "448/448 [==============================] - 24s 54ms/step - loss: 1.1154 - accuracy: 0.5782 - val_loss: 1.0698 - val_accuracy: 0.5986\n",
            "Epoch 41/50\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.1092 - accuracy: 0.5807 - val_loss: 1.1074 - val_accuracy: 0.5804\n",
            "Epoch 42/50\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.1105 - accuracy: 0.5831 - val_loss: 1.1040 - val_accuracy: 0.5896\n",
            "Epoch 43/50\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.1066 - accuracy: 0.5841 - val_loss: 1.0755 - val_accuracy: 0.5931\n",
            "Epoch 44/50\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 1.1024 - accuracy: 0.5839 - val_loss: 1.0655 - val_accuracy: 0.6034\n",
            "Epoch 45/50\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.1058 - accuracy: 0.5829 - val_loss: 1.0546 - val_accuracy: 0.6031\n",
            "Epoch 46/50\n",
            "448/448 [==============================] - 23s 52ms/step - loss: 1.0947 - accuracy: 0.5838 - val_loss: 1.0630 - val_accuracy: 0.5964\n",
            "Epoch 47/50\n",
            "448/448 [==============================] - 24s 54ms/step - loss: 1.1008 - accuracy: 0.5863 - val_loss: 1.0557 - val_accuracy: 0.6007\n",
            "Epoch 48/50\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.0969 - accuracy: 0.5862 - val_loss: 1.0497 - val_accuracy: 0.6096\n",
            "Epoch 49/50\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.0928 - accuracy: 0.5922 - val_loss: 1.0744 - val_accuracy: 0.5910\n",
            "Epoch 50/50\n",
            "448/448 [==============================] - 24s 53ms/step - loss: 1.0892 - accuracy: 0.5882 - val_loss: 1.0801 - val_accuracy: 0.5883\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(datagen.flow(X_train.reshape(-1, 48, 48, 1), y_train, batch_size=64),\n",
        "                    steps_per_epoch=len(X_train) // 64,\n",
        "                    epochs=50,\n",
        "                    validation_data=(X_test.reshape(-1, 48, 48, 1), y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydhie_YQD3U0",
        "outputId": "55a4e8b5-8cc4-44b2-b593-f92a11e4de9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 2s 9ms/step\n",
            "Accuracy: 0.5883254388409027\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test.reshape(-1, 48, 48, 1))\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "69gVQCr3LP_m"
      },
      "outputs": [],
      "source": [
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Mwt9aN8OLaUC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-16 23:48:50.249 python[65225:4463952] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jDmvfzVDLdWh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_img = gray[y:y+h, x:x+w]\n",
        "        face_img = cv2.resize(face_img, (48, 48))\n",
        "        face_img = face_img.reshape(1, 48, 48, 1) / 255.0\n",
        "\n",
        "        emotion_idx = np.argmax(model.predict(face_img))\n",
        "        emotion = emotion_labels[emotion_idx]\n",
        "\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imshow('Emotion Recognition', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQTAMVAtLk7n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorenv",
      "language": "python",
      "name": "tensorenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
