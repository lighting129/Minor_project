{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    'ImageDataset/train',\n",
    "    target_size=(48,48),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = train_data_gen.flow_from_directory(\n",
    "    'ImageDataset/test',\n",
    "    target_size=(48,48),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "emotional_model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=[48,48,1]))\n",
    "emotional_model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "emotional_model.add(MaxPooling2D(pool_size=2))\n",
    "emotional_model.add(Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "emotional_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "emotional_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "emotional_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "emotional_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_model.add(Flatten())\n",
    "emotional_model.add(Dense(1024,activation='relu'))\n",
    "emotional_model.add(Dropout(0.5))\n",
    "emotional_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 853ms/step - accuracy: 0.2422 - loss: 1.8325 - val_accuracy: 0.2937 - val_loss: 1.7612\n",
      "Epoch 2/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 208ms/step - accuracy: 0.3308 - loss: 1.6910 - val_accuracy: 0.4087 - val_loss: 1.5627\n",
      "Epoch 3/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 192ms/step - accuracy: 0.3973 - loss: 1.5631 - val_accuracy: 0.4368 - val_loss: 1.4661\n",
      "Epoch 4/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 195ms/step - accuracy: 0.4316 - loss: 1.4902 - val_accuracy: 0.4687 - val_loss: 1.4063\n",
      "Epoch 5/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 199ms/step - accuracy: 0.4608 - loss: 1.4131 - val_accuracy: 0.4869 - val_loss: 1.3496\n",
      "Epoch 6/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 203ms/step - accuracy: 0.4842 - loss: 1.3531 - val_accuracy: 0.5078 - val_loss: 1.3137\n",
      "Epoch 7/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 207ms/step - accuracy: 0.5035 - loss: 1.3025 - val_accuracy: 0.5132 - val_loss: 1.2855\n",
      "Epoch 8/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 211ms/step - accuracy: 0.5158 - loss: 1.2772 - val_accuracy: 0.5152 - val_loss: 1.2768\n",
      "Epoch 9/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 222ms/step - accuracy: 0.5383 - loss: 1.2305 - val_accuracy: 0.5273 - val_loss: 1.2486\n",
      "Epoch 10/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 219ms/step - accuracy: 0.5485 - loss: 1.1934 - val_accuracy: 0.5447 - val_loss: 1.1980\n",
      "Epoch 11/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 213ms/step - accuracy: 0.5634 - loss: 1.1604 - val_accuracy: 0.5467 - val_loss: 1.1862\n",
      "Epoch 12/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.5685 - loss: 1.1506 - val_accuracy: 0.5538 - val_loss: 1.1723\n",
      "Epoch 13/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 217ms/step - accuracy: 0.5781 - loss: 1.1221 - val_accuracy: 0.5602 - val_loss: 1.1500\n",
      "Epoch 14/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 218ms/step - accuracy: 0.5964 - loss: 1.0934 - val_accuracy: 0.5641 - val_loss: 1.1565\n",
      "Epoch 15/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.6024 - loss: 1.0636 - val_accuracy: 0.5716 - val_loss: 1.1309\n",
      "Epoch 16/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 214ms/step - accuracy: 0.6118 - loss: 1.0395 - val_accuracy: 0.5740 - val_loss: 1.1284\n",
      "Epoch 17/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 214ms/step - accuracy: 0.6208 - loss: 1.0117 - val_accuracy: 0.5783 - val_loss: 1.1108\n",
      "Epoch 18/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 219ms/step - accuracy: 0.6303 - loss: 0.9943 - val_accuracy: 0.5818 - val_loss: 1.1108\n",
      "Epoch 19/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 217ms/step - accuracy: 0.6432 - loss: 0.9645 - val_accuracy: 0.5917 - val_loss: 1.0886\n",
      "Epoch 20/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 216ms/step - accuracy: 0.6509 - loss: 0.9435 - val_accuracy: 0.5908 - val_loss: 1.1000\n",
      "Epoch 21/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 223ms/step - accuracy: 0.6624 - loss: 0.9233 - val_accuracy: 0.5936 - val_loss: 1.0770\n",
      "Epoch 22/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 214ms/step - accuracy: 0.6763 - loss: 0.8877 - val_accuracy: 0.5957 - val_loss: 1.0800\n",
      "Epoch 23/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 219ms/step - accuracy: 0.6765 - loss: 0.8751 - val_accuracy: 0.5967 - val_loss: 1.0811\n",
      "Epoch 24/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 213ms/step - accuracy: 0.6827 - loss: 0.8586 - val_accuracy: 0.5978 - val_loss: 1.0773\n",
      "Epoch 25/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 216ms/step - accuracy: 0.6913 - loss: 0.8311 - val_accuracy: 0.5991 - val_loss: 1.0748\n",
      "Epoch 26/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 216ms/step - accuracy: 0.7036 - loss: 0.8152 - val_accuracy: 0.6009 - val_loss: 1.0748\n",
      "Epoch 27/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 224ms/step - accuracy: 0.7144 - loss: 0.7822 - val_accuracy: 0.6041 - val_loss: 1.0746\n",
      "Epoch 28/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 216ms/step - accuracy: 0.7221 - loss: 0.7569 - val_accuracy: 0.6043 - val_loss: 1.0904\n",
      "Epoch 29/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 216ms/step - accuracy: 0.7352 - loss: 0.7309 - val_accuracy: 0.6085 - val_loss: 1.0759\n",
      "Epoch 30/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 216ms/step - accuracy: 0.7415 - loss: 0.7052 - val_accuracy: 0.6056 - val_loss: 1.0906\n",
      "Epoch 31/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 219ms/step - accuracy: 0.7486 - loss: 0.6809 - val_accuracy: 0.6085 - val_loss: 1.0833\n",
      "Epoch 32/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 220ms/step - accuracy: 0.7558 - loss: 0.6701 - val_accuracy: 0.6152 - val_loss: 1.0803\n",
      "Epoch 33/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.7658 - loss: 0.6424 - val_accuracy: 0.6109 - val_loss: 1.0900\n",
      "Epoch 34/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 217ms/step - accuracy: 0.7810 - loss: 0.6063 - val_accuracy: 0.6110 - val_loss: 1.1129\n",
      "Epoch 35/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 218ms/step - accuracy: 0.7871 - loss: 0.5894 - val_accuracy: 0.6187 - val_loss: 1.0863\n",
      "Epoch 36/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.7902 - loss: 0.5804 - val_accuracy: 0.6173 - val_loss: 1.1066\n",
      "Epoch 37/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 219ms/step - accuracy: 0.7958 - loss: 0.5621 - val_accuracy: 0.6187 - val_loss: 1.1102\n",
      "Epoch 38/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.8110 - loss: 0.5270 - val_accuracy: 0.6206 - val_loss: 1.1159\n",
      "Epoch 39/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.8064 - loss: 0.5263 - val_accuracy: 0.6193 - val_loss: 1.1292\n",
      "Epoch 40/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 218ms/step - accuracy: 0.8154 - loss: 0.5109 - val_accuracy: 0.6169 - val_loss: 1.1226\n",
      "Epoch 41/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 213ms/step - accuracy: 0.8224 - loss: 0.4858 - val_accuracy: 0.6222 - val_loss: 1.1352\n",
      "Epoch 42/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.8306 - loss: 0.4713 - val_accuracy: 0.6194 - val_loss: 1.1458\n",
      "Epoch 43/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.8345 - loss: 0.4601 - val_accuracy: 0.6209 - val_loss: 1.1645\n",
      "Epoch 44/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 214ms/step - accuracy: 0.8402 - loss: 0.4390 - val_accuracy: 0.6216 - val_loss: 1.1520\n",
      "Epoch 45/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 214ms/step - accuracy: 0.8507 - loss: 0.4226 - val_accuracy: 0.6223 - val_loss: 1.1597\n",
      "Epoch 46/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.8509 - loss: 0.4126 - val_accuracy: 0.6216 - val_loss: 1.1685\n",
      "Epoch 47/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 214ms/step - accuracy: 0.8619 - loss: 0.3914 - val_accuracy: 0.6216 - val_loss: 1.1786\n",
      "Epoch 48/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.8583 - loss: 0.3878 - val_accuracy: 0.6219 - val_loss: 1.2032\n",
      "Epoch 49/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 214ms/step - accuracy: 0.8707 - loss: 0.3696 - val_accuracy: 0.6220 - val_loss: 1.1983\n",
      "Epoch 50/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 214ms/step - accuracy: 0.8720 - loss: 0.3586 - val_accuracy: 0.6227 - val_loss: 1.2241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x165f21a71d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotional_model.fit(x = train_generator,epochs = 50,validation_data = test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = emotional_model.to_json()\n",
    "with open(\"emotion_model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_model.save_weights('emotion_model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
